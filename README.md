# MineObserver 2.0


Official Implementation of <b>"MineObserver 2.0: A Deep Learning & In-Game Framework for Assessing Natural Language Descriptions of Minecraft Imagery" </b>
by <a href="https://jmahajan117.github.io/"> Jay Mahajan </a>, 
<a href= "https://www.linkedin.com/in/samhum/">Samuel Hum </a>,
<a href="https://henhapl.me/index.html">Jack Henhapl </a>,
<a href = "https://www.linkedin.com/in/dyunus/">Diya Yunus</a>,
<a href = "https://www.linkedin.com/in/matt-gadbury-74a87265/">Matthew Gadbury </a>,
<a href="https://emicb.com/">Emi Brown</a>,
<a href="https://jeffginger.com/#intro">Jeff Ginger</a>, and
<a href="https://education.illinois.edu/faculty/h-chad-lane">H. Chad Lane</a>

<a href="">[Paper]</a> <a href="">[Project Page]</a>


<b>MineObserver 2.0</b> is an AI framework that uses Computer Vision and Natural Language Processing for assessing the accuracy of learner-generated descriptions of Minecraft images that include some scientifically relevant content. The system automatically assesses the accuracy of participant observations, written in natural language, made during science learning activities that take place in Minecraft. We demonstrate our system working in real-time and describe a teacher dashboard to showcase observations, both of which advance our previous work. We present the results of a study showing that MineObserver 2.0 improves over its predecessor both in perceived accuracy of the system's generated descriptions as well as in usefulness of the system's feedback. In future work, we intend improve system generated descriptions to give more teacher control and shift the system to perform continuous learning to more rapidly respond to novel observations made by learners.




## Teaser
[![Video](https://img.youtube.com/vi/nMVW_5S9xYU/maxresdefault.jpg)](https://www.youtube.com/watch?=v=nMVW_5S9xYU)
            

